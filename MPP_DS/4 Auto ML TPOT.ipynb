{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esteban.londono\\AppData\\Local\\Continuum\\anaconda3\\envs\\AutoML\\lib\\site-packages\\deap\\tools\\_hypervolume\\pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n",
      "C:\\Users\\esteban.londono\\AppData\\Local\\Continuum\\anaconda3\\envs\\AutoML\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\esteban.londono\\AppData\\Local\\Continuum\\anaconda3\\envs\\AutoML\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#Fundamental librarys to math and stats process\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import scipy.stats as ss\n",
    "import math\n",
    "#data prepared\n",
    "import pandas as pd\n",
    "\n",
    "#ML preprocessi\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import feature_selection as fs\n",
    "\n",
    "# ML algorithms models\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor \n",
    "from sklearn import linear_model as lm\n",
    "import xgboost as xgb\n",
    "\n",
    "# ML Evaluations\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "\n",
    "#Auto ML\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "#Ploting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'population', 'renter_occupied_households',\n",
      "       'pct_renter_occupied', 'median_gross_rent', 'rent_burden', 'pct_white',\n",
      "       'pct_af_am', 'pct_hispanic', 'pct_am_ind', 'pct_asian', 'pct_nh_pi',\n",
      "       'pct_multiple', 'pct_other', 'poverty_rate', 'pct_civilian_labor',\n",
      "       'pct_unemployment', 'pct_uninsured_adults', 'pct_uninsured_children',\n",
      "       'pct_adult_obesity', 'pct_diabetes', 'pct_physical_inactivity',\n",
      "       'heart_disease_mortality_per_100k', 'pct_female',\n",
      "       'pct_below_18_years_of_age', 'pct_aged_65_years_and_older',\n",
      "       'pct_adults_less_than_a_high_school_diploma',\n",
      "       'pct_adults_with_high_school_diploma', 'pct_adults_with_some_college',\n",
      "       'pct_adults_bachelors_or_higher', 'birth_rate_per_1k',\n",
      "       'death_rate_per_1k', 'RUCC1', 'RUCC2', 'RUCC3', 'RUCC4', 'RUCC5',\n",
      "       'RUCC6', 'RUCC7', 'RUCC8', 'RUCC9', 'ECT1', 'ECT2', 'ECT3', 'ECT4',\n",
      "       'ECT5', 'ECT6', 'UI1', 'UI2', 'UI3', 'UI4', 'UI5', 'UI6', 'UI7', 'UI8',\n",
      "       'UI9', 'UI10', 'UI11', 'UI12', 'YA', 'YB', 'evictions'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'population', 'renter_occupied_households',\n",
      "       'pct_renter_occupied', 'median_gross_rent', 'rent_burden', 'pct_white',\n",
      "       'pct_af_am', 'pct_hispanic', 'pct_am_ind', 'pct_asian', 'pct_nh_pi',\n",
      "       'pct_multiple', 'pct_other', 'poverty_rate', 'pct_civilian_labor',\n",
      "       'pct_unemployment', 'pct_uninsured_adults', 'pct_uninsured_children',\n",
      "       'pct_adult_obesity', 'pct_diabetes', 'pct_physical_inactivity',\n",
      "       'heart_disease_mortality_per_100k', 'pct_female',\n",
      "       'pct_below_18_years_of_age', 'pct_aged_65_years_and_older',\n",
      "       'pct_adults_less_than_a_high_school_diploma',\n",
      "       'pct_adults_with_high_school_diploma', 'pct_adults_with_some_college',\n",
      "       'pct_adults_bachelors_or_higher', 'birth_rate_per_1k',\n",
      "       'death_rate_per_1k', 'RUCC1', 'RUCC2', 'RUCC3', 'RUCC4', 'RUCC5',\n",
      "       'RUCC6', 'RUCC7', 'RUCC8', 'RUCC9', 'ECT1', 'ECT2', 'ECT3', 'ECT4',\n",
      "       'ECT5', 'ECT6', 'UI1', 'UI2', 'UI3', 'UI4', 'UI5', 'UI6', 'UI7', 'UI8',\n",
      "       'UI9', 'UI10', 'UI11', 'UI12', 'YA', 'YB', 'evictions'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_trf = (pd.read_csv('df_trf.csv'))\n",
    "df_enc = (pd.read_csv('df_enc.csv'))\n",
    "print(df_trf.columns)\n",
    "print(df_enc.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trf= df_trf.drop(['Unnamed: 0','population','evictions'], axis=1)\n",
    "y_trf= df_trf['evictions']\n",
    "x_trf = np.array(x_trf)\n",
    "y_trf=np.array(y_trf)\n",
    "\n",
    "x_enc= df_enc.drop(['Unnamed: 0','population','evictions'], axis=1)\n",
    "y_enc= df_enc['evictions']\n",
    "x_enc = np.array(x_enc)\n",
    "y_enc=np.array(y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2546, 59)\n",
      "(2546,)\n",
      "(2546, 59)\n",
      "(2546,)\n"
     ]
    }
   ],
   "source": [
    "print(x_enc.shape)\n",
    "print(y_enc.shape)\n",
    "\n",
    "print(x_trf.shape)\n",
    "print(y_trf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splt train test\n",
    "nr.seed(9988)\n",
    "xtrf_train, xtrf_test, ytrf_train, ytrf_test = train_test_split(x_trf,y_trf,test_size=0.1)\n",
    "xenc_train, xenc_test, yenc_train, yenc_test = train_test_split(x_enc,y_enc,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=440, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8972676667593122\n",
      "Generation 2 - Current best internal CV score: 0.8972676667593122\n",
      "Generation 3 - Current best internal CV score: 0.8981116470606729\n",
      "Generation 4 - Current best internal CV score: 0.8981116470606729\n",
      "Generation 5 - Current best internal CV score: 0.8983278137611477\n",
      "Generation 6 - Current best internal CV score: 0.9003487333248789\n",
      "Generation 7 - Current best internal CV score: 0.9003487333248789\n",
      "Generation 8 - Current best internal CV score: 0.900808270010371\n",
      "Generation 9 - Current best internal CV score: 0.9012477054083922\n",
      "Generation 10 - Current best internal CV score: 0.9021060044881622\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(ExtraTreesRegressor(KNeighborsRegressor(PolynomialFeatures(MinMaxScaler(input_matrix), degree=2, include_bias=False, interaction_only=False), n_neighbors=34, p=1, weights=uniform), bootstrap=False, max_features=0.45, min_samples_leaf=5, min_samples_split=15, n_estimators=100), bootstrap=False, max_features=0.2, min_samples_leaf=1, min_samples_split=3, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=440, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8158982075444529\n",
      "Generation 2 - Current best internal CV score: 0.8298470993360532\n",
      "Generation 3 - Current best internal CV score: 0.8307280768765489\n",
      "Generation 4 - Current best internal CV score: 0.8320146362206768\n",
      "Generation 5 - Current best internal CV score: 0.8587594297383273\n",
      "Generation 6 - Current best internal CV score: 0.8587594297383273\n",
      "Generation 7 - Current best internal CV score: 0.8587594297383273\n",
      "Generation 8 - Current best internal CV score: 0.8609316126439186\n",
      "Generation 9 - Current best internal CV score: 0.8771592854925728\n",
      "Generation 10 - Current best internal CV score: 0.8784382472941576\n",
      "\n",
      "Best pipeline: XGBRegressor(RandomForestRegressor(input_matrix, bootstrap=False, max_features=0.5, min_samples_leaf=2, min_samples_split=4, n_estimators=100), learning_rate=1.0, max_depth=5, min_child_weight=12, n_estimators=100, nthread=1, subsample=0.8500000000000001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_trf = TPOTRegressor(generations=7, population_size=30, cv=5,verbosity=2, scoring='r2')\n",
    "tpot_trf.fit(xtrf_train, ytrf_train)\n",
    "tpot_trf.export('tpot_pipeline_trf.py')\n",
    "\n",
    "tpot_enc = TPOTRegressor(generations=7, population_size=30, cv=5,verbosity=2, scoring='r2')\n",
    "tpot_enc.fit(xenc_train, yenc_train)\n",
    "tpot_enc.export('tpot_pipeline_enc.py')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trf pipeline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler,FunctionTransformer, PolynomialFeatures\n",
    "from copy import copy\n",
    "\n",
    "from tpot.builtins import StackingEstimator\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipeline_trf1 = make_pipeline(\n",
    "    Normalizer(norm=\"l2\"),\n",
    "    RandomForestRegressor(bootstrap=False,\n",
    "                          max_features=0.7000000000000001,\n",
    "                          min_samples_leaf=3,\n",
    "                          min_samples_split=2,\n",
    "                          n_estimators=100)\n",
    ")\n",
    "\n",
    "# Average CV score on the training set was:0.8812547047881732\n",
    "\n",
    "pipeline_trf2 = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    RandomForestRegressor(bootstrap=False,\n",
    "                          max_features=0.7000000000000001,\n",
    "                          min_samples_leaf=6,\n",
    "                          min_samples_split=2,\n",
    "                          n_estimators=100))\n",
    "\n",
    "# Average CV score on the training set was:0.8925027080134283# \n",
    "pipeline_trf3 = make_pipeline(\n",
    "    make_union( FunctionTransformer(copy),FunctionTransformer(copy)),\n",
    "    ExtraTreesRegressor(\n",
    "        bootstrap=False,\n",
    "        max_features=0.7500000000000001,\n",
    "        min_samples_leaf=3,\n",
    "        min_samples_split=3, \n",
    "        n_estimators=100)\n",
    ")\n",
    "\n",
    "\n",
    "#Average CV score on the training set was:0.9021060044881622\n",
    "pipeline_trf4 = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),\n",
    "    StackingEstimator(\n",
    "        estimator=KNeighborsRegressor(\n",
    "            n_neighbors=34, p=1, weights=\"uniform\")),\n",
    "    StackingEstimator(\n",
    "        estimator=ExtraTreesRegressor(\n",
    "            bootstrap=False,\n",
    "            max_features=0.45,\n",
    "            min_samples_leaf=5,\n",
    "            min_samples_split=15,\n",
    "            n_estimators=100)),\n",
    "    ExtraTreesRegressor(\n",
    "        bootstrap=False,\n",
    "        max_features=0.2,\n",
    "        min_samples_leaf=1,\n",
    "        min_samples_split=3,\n",
    "        n_estimators=100)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator,OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import RidgeCV, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# Average CV score on the training set was:0.8767668328812122\n",
    "pipeline_enc1 = make_pipeline(\n",
    "    StackingEstimator(estimator=ElasticNetCV(l1_ratio=0.9500000000000001, tol=1e-05)),\n",
    "    RandomForestRegressor(bootstrap=False, max_features=0.1, min_samples_leaf=1, min_samples_split=4, n_estimators=100)\n",
    ")\n",
    "\n",
    "# Average CV score on the training set was:0.8630661690341384\n",
    "\n",
    "pipeline_enc2 = RandomForestRegressor(bootstrap=False,\n",
    "                                      max_features=0.25, \n",
    "                                      min_samples_leaf=2,\n",
    "                                      min_samples_split=2, \n",
    "                                      n_estimators=100)\n",
    "\n",
    "# Average CV score on the training set was:0.8409039139854155\n",
    "pipeline_enc3 = make_pipeline(\n",
    "    OneHotEncoder(minimum_fraction=0.1, sparse=False, threshold=10),\n",
    "    StackingEstimator(\n",
    "        estimator=XGBRegressor(\n",
    "            learning_rate=0.01,\n",
    "            max_depth=5,\n",
    "            min_child_weight=1,\n",
    "            n_estimators=100, \n",
    "            nthread=1,\n",
    "            subsample=0.6000000000000001)),\n",
    "    RidgeCV()\n",
    ")\n",
    "\n",
    "# Average CV score on the training set was:0.8784382472941576\n",
    "\n",
    "pipeline_enc4 = make_pipeline(\n",
    "    StackingEstimator(estimator=RandomForestRegressor(bootstrap=False, max_features=0.5, min_samples_leaf=2, min_samples_split=4, n_estimators=100)),\n",
    "    XGBRegressor(learning_rate=1.0, max_depth=5, min_child_weight=12, n_estimators=100, nthread=1, subsample=0.8500000000000001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('stackingestimator', StackingEstimator(estimator=RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
       "           max_features=0.5, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=2, min_samples_split=4,\n",
       "      ...=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8500000000000001))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_trf1.fit(xtrf_train,ytrf_train)\n",
    "pipeline_trf2.fit(xtrf_train,ytrf_train)\n",
    "pipeline_trf3.fit(xtrf_train,ytrf_train)\n",
    "pipeline_trf4.fit(xtrf_train,ytrf_train)\n",
    "\n",
    "pipeline_enc1.fit(xenc_train,yenc_train)\n",
    "pipeline_enc2.fit(xenc_train,yenc_train)\n",
    "pipeline_enc3.fit(xenc_train,yenc_train)\n",
    "pipeline_enc4.fit(xenc_train,yenc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "Results_pipeline_trf1 = cross_validate(pipeline_trf1,x_trf,y_trf,scoring=\"r2\",cv=5)\n",
    "Results_pipeline_trf2 = cross_validate(pipeline_trf2,x_trf,y_trf,scoring=\"r2\",cv=5)\n",
    "Results_pipeline_trf3 = cross_validate(pipeline_trf3,x_trf,y_trf,scoring=\"r2\",cv=5)\n",
    "Results_pipeline_trf4 = cross_validate(pipeline_trf4,x_trf,y_trf,scoring=\"r2\",cv=5)\n",
    "\n",
    "Results_pipeline_enc1 = cross_validate(pipeline_enc1 ,x_enc,y_enc,scoring=\"r2\",cv=5)\n",
    "Results_pipeline_enc2 = cross_validate(pipeline_enc2 ,x_enc,y_enc,scoring=\"r2\",cv=5)\n",
    "Results_pipeline_enc3 = cross_validate(pipeline_enc3 ,x_enc,y_enc,scoring=\"r2\",cv=5)\n",
    "Results_pipeline_enc4 = cross_validate(pipeline_enc1 ,x_enc,y_enc,scoring=\"r2\",cv=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trf1 train=0.9927446573716671\n",
      "trf1 test=0.8953355755880231\n",
      "trf2 train=0.9735647980131018\n",
      "trf2 test=0.886937528296154\n",
      "trf3 train=0.9835978755703723\n",
      "trf3 test=0.8991001469233331\n",
      "trf4 train=0.999800829858955\n",
      "trf4 test=0.90655091014772\n"
     ]
    }
   ],
   "source": [
    "pipeline_trf1_test_scores = Results_pipeline_trf1['test_score']\n",
    "pipeline_trf1_train_scores = Results_pipeline_trf1['train_score']\n",
    "\n",
    "pipeline_trf2_test_scores = Results_pipeline_trf2['test_score']\n",
    "pipeline_trf2_train_scores = Results_pipeline_trf2['train_score']\n",
    "\n",
    "pipeline_trf3_test_scores = Results_pipeline_trf3['test_score']\n",
    "pipeline_trf3_train_scores = Results_pipeline_trf3['train_score']\n",
    "\n",
    "pipeline_trf4_test_scores = Results_pipeline_trf4['test_score']\n",
    "pipeline_trf4_train_scores = Results_pipeline_trf4['train_score']\n",
    "\n",
    "\n",
    "\n",
    "print('trf1 train='+str(np.mean(pipeline_trf1_train_scores)))\n",
    "print('trf1 test='+str(np.mean(pipeline_trf1_test_scores)))\n",
    "\n",
    "print('trf2 train='+str(np.mean(pipeline_trf2_train_scores)))\n",
    "print('trf2 test='+str(np.mean(pipeline_trf2_test_scores)))\n",
    "\n",
    "print('trf3 train='+str(np.mean(pipeline_trf3_train_scores)))\n",
    "print('trf3 test='+str(np.mean(pipeline_trf3_test_scores)))\n",
    "\n",
    "\n",
    "print('trf4 train='+str(np.mean(pipeline_trf4_train_scores)))\n",
    "print('trf4 test='+str(np.mean(pipeline_trf4_test_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc1 train=0.9957655323298973\n",
      "enc1 test=0.8777742677025924\n",
      "enc2 train=0.9855258295229283\n",
      "enc2 test=0.8621373103077492\n",
      "enc3 train=0.940562480494249\n",
      "enc3 test=0.8421084052942461\n",
      "enc4 train=0.9961360011231338\n",
      "enc4 test=0.8754169189689616\n"
     ]
    }
   ],
   "source": [
    "pipeline_enc1_test_scores = Results_pipeline_enc1['test_score']\n",
    "pipeline_enc1_train_scores = Results_pipeline_enc1['train_score']\n",
    "\n",
    "pipeline_enc2_test_scores = Results_pipeline_enc2['test_score']\n",
    "pipeline_enc2_train_scores = Results_pipeline_enc2['train_score']\n",
    "\n",
    "pipeline_enc3_test_scores = Results_pipeline_enc3['test_score']\n",
    "pipeline_enc3_train_scores = Results_pipeline_enc3['train_score']\n",
    "\n",
    "pipeline_enc4_test_scores = Results_pipeline_enc4['test_score']\n",
    "pipeline_enc4_train_scores = Results_pipeline_enc4['train_score']\n",
    "\n",
    "\n",
    "\n",
    "print('enc1 train='+str(np.mean(pipeline_enc1_train_scores)))\n",
    "print('enc1 test='+str(np.mean(pipeline_enc1_test_scores)))\n",
    "\n",
    "print('enc2 train='+str(np.mean(pipeline_enc2_train_scores)))\n",
    "print('enc2 test='+str(np.mean(pipeline_enc2_test_scores)))\n",
    "\n",
    "print('enc3 train='+str(np.mean(pipeline_enc3_train_scores)))\n",
    "print('enc3 test='+str(np.mean(pipeline_enc3_test_scores)))\n",
    "\n",
    "print('enc4 train='+str(np.mean(pipeline_enc4_train_scores)))\n",
    "print('enc4 test='+str(np.mean(pipeline_enc4_test_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8807304940704728\n",
      "0.9319104699386246\n"
     ]
    }
   ],
   "source": [
    "pipeline_trf=pipeline_trf4.fit(xtrf_train,ytrf_train)\n",
    "pipeline_enc=pipeline_enc1.fit(xenc_train,yenc_train)\n",
    "\n",
    "print(pipeline_trf4.score(xtrf_test,ytrf_test))\n",
    "print(pipeline_enc1.score(xenc_test,yenc_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preidction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trf=pd.read_csv('df_test_trf.csv')\n",
    "test_trf=test_trf.drop(['Unnamed: 0','median_household_income','median_property_value'],axis=1)\n",
    "test_trf= np.array(test_trf)\n",
    "\n",
    "test_enc=pd.read_csv('df_test_enc.csv')\n",
    "test_enc=test_enc.drop(['Unnamed: 0','median_household_income','median_property_value'],axis=1)\n",
    "test_enc= np.array(test_trf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        evictions\n",
       "row_id           \n",
       "0             544\n",
       "1             247\n",
       "2               0\n",
       "3              10\n",
       "4             132"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AML_Prediction=pipeline_trf.predict(test_trf)\n",
    "AML_Prediction= pd.DataFrame(AML_Prediction,columns=['evictions'])\n",
    "AML_Prediction.index.names=['row_id']\n",
    "AML_Prediction['evictions']=np.expm1(AML_Prediction['evictions'])\n",
    "AML_Prediction['evictions']=AML_Prediction['evictions'].astype(np.int64)\n",
    "AML_Prediction.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "AML_Prediction.to_csv('AML_Prediction_trf1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        evictions\n",
       "row_id           \n",
       "0             292\n",
       "1             638\n",
       "2             124\n",
       "3             157\n",
       "4             258"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AML_Prediction2=pipeline_enc.predict(test_enc)\n",
    "AML_Prediction2= pd.DataFrame(AML_Prediction2,columns=['evictions'])\n",
    "AML_Prediction2.index.names=['row_id']\n",
    "AML_Prediction2['evictions']=AML_Prediction2['evictions'].astype(np.int64)\n",
    "AML_Prediction2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "AML_Prediction2.to_csv('AML_Prediction_Enc1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
